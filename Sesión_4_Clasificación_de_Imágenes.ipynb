{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf5Nc2pWH7-A"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C2ETbjSQZiYt",
        "outputId": "16349e9d-23f4-47dd-9b32-fffa334da7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqRgv_H2IBou"
      },
      "source": [
        "# 1. Clasificación general de objetos\n",
        "\n",
        "1. Carga el modelo preentrenado de detección de objetos en imagenet `\"microsoft/beit-base-patch16-224\"`\n",
        "\n",
        "2. Clasifica la siguiente imagen directamente desde la URL\n",
        "\n",
        "  ```\n",
        "  image_url = \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\"\n",
        "  classifier(image_url)\n",
        "  ```\n",
        "\n",
        "3. Busca una imagen en internet de una manzana, copiando la URL directa (Google>Abrir imagen en pestaña nueva>Copiar url\n",
        "\n",
        "4. Comprueba como el modelo la clasifica\n",
        "\n",
        "5. Monta una demo de Gradio con la componente de Imagen gr.Image(type=\"pil\"), usa la webcam para hacer fotos de objetos e identificarlos\n",
        "\n",
        "6. Añade ejemplos de image a la demo (directamente el url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OqrJNTt3JOQb",
        "outputId": "1615a405-79d1-4268-a955-40f396568368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(task=\"image-classification\", model=\"microsoft/beit-base-patch16-224\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mlbVTvzJSqz",
        "outputId": "38728611-871d-44da-83e2-3515d206703b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'macaw', 'score': 0.8165549635887146},\n",
              " {'label': 'African grey, African gray, Psittacus erithacus',\n",
              "  'score': 0.025080500170588493},\n",
              " {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',\n",
              "  'score': 0.005151170771569014},\n",
              " {'label': 'lorikeet', 'score': 0.002157665090635419},\n",
              " {'label': 'toucan', 'score': 0.0014293864369392395}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "image_url = \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\"\n",
        "classifier(image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjLBzGuMpQFU",
        "outputId": "b2b433ea-3318-4b34-a5ad-d1db314769cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'Granny Smith', 'score': 0.6352676749229431},\n",
              " {'label': 'orange', 'score': 0.008518175221979618},\n",
              " {'label': 'banana', 'score': 0.004737537354230881},\n",
              " {'label': 'strawberry', 'score': 0.00421148119494319},\n",
              " {'label': 'grocery store, grocery, food market, market',\n",
              "  'score': 0.0037635830231010914}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "image_url = \"data:image/jpeg;base64,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\"\n",
        "classifier(image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "rNyttqfmszNt",
        "outputId": "c0eac85d-cbf7-40ee-f85f-986217d7be9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2025-3-27 Python-3.11.11 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cc9df81fe314fc1b95.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cc9df81fe314fc1b95.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Cargar un modelo YOLOv5 pre-entrenado (ejemplo, \"yolov5s\")\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # Necesitas internet para la primera descarga\n",
        "model.eval()\n",
        "\n",
        "\n",
        "def detect_objects(image):\n",
        "    \"\"\"Detecta objetos en la imagen.\"\"\"\n",
        "    results = model(image)\n",
        "    results.render()  # Renders the bounding boxes on the image\n",
        "\n",
        "    # Extract labels and confidence scores\n",
        "    labels = results.pandas().xyxy[0]['name'].tolist()\n",
        "    confidence_scores = results.pandas().xyxy[0]['confidence'].tolist()\n",
        "\n",
        "    # Create a dictionary of labels and confidence scores\n",
        "    detections = dict(zip(labels, confidence_scores))\n",
        "    return Image.fromarray(results.ims[0]), detections\n",
        "\n",
        "# Crear la interfaz de Gradio\n",
        "# Removing source=\"webcam\" from gr.Image and using video/live instead\n",
        "iface = gr.Interface(\n",
        "    fn=detect_objects,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Capture an image\"),\n",
        "    outputs=[gr.Image(label=\"Detected Objects\"), gr.Label(label=\"Detections\")],\n",
        "    # Specifying video and live to enable live webcam input\n",
        "    live=True,\n",
        "    title=\"Object Detection with Webcam\",\n",
        "    description=\"Capture an image with your webcam and the model will detect objects.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8K-sBmsNGQ-"
      },
      "source": [
        "# 2. Clasificación cusotmizada de objetos\n",
        "\n",
        "1. Define una lista de 3 categorías de objetos que quieras clasificar\n",
        "\n",
        "2. Usa el modelo preentrenado \"openai/clip-vit-large-patch14\" con las categorías predefinidas\n",
        "\n",
        "  ```\n",
        "  classifier(image_url, candidate_labels = categorias)\n",
        "  ```\n",
        "\n",
        "3. Crea una demo donde el usuario pueda clasificar imágenes en base a las categorias definidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqI9gleINWaz",
        "outputId": "228f785e-9d23-49ce-f212-51963cb3e4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "categorias = [\"banana\", \"apple\", \"orange\"]\n",
        "classifier = pipeline(model=\"openai/clip-vit-large-patch14\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6BTVr9rffCIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "6c3d018c-f198-4673-ae98-5f01cec1798e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ca6e194e8cc4dbd4da.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ca6e194e8cc4dbd4da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def classify_image(img):\n",
        "    results = classifier(img, candidate_labels = categorias)\n",
        "    return {item[\"label\"]: item[\"score\"] for item in results}\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"📸 Sube o toma una foto de una fruta\"),\n",
        "    outputs=gr.Label(label=\"Top Predicciones\"),\n",
        "    title=\"Clasificador de Frutas\",\n",
        "    description=\"Usa la cámara o sube una imagen de una fruta.\",\n",
        "    examples=[\n",
        "        [\"https://resizer.glanacion.com/resizer/v2/es-una-de-las-frutas-mas-practicas-y-versatiles-BJB5RPAYRNEOTK6D7JAHQ6ZCCA.jpg?auth=df1322d6cf241632aaf3fe298f710954fce5a4cf0f7b521ba939e6681346e9a5&width=768&quality=70&smart=false\"],\n",
        "    ],\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Xf5Nc2pWH7-A"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}